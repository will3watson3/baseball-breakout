import pandas as pd
import numpy as np
from glob import glob
import re


import pandas as pd
import numpy as np
import re

# -------- CONFIG --------
DATA_PATHS = {
    2021: "../data/raw/savant_2021.csv",
    2022: "../data/raw/savant_2022.csv",
    2023: "../data/raw/savant_2023.csv",
    2024: "../data/raw/savant_2024.csv",
    2025: "../data/raw/savant_2025.csv",
}

OUTPUT_PATH = "../outputs/combined_breakouts_and_nonbreakouts_2022_2025_ratio_features.csv"

MIN_SEASON = 2021
MIN_PA_FOR_ROW   = 100   # to include a season row at all
MIN_PA_FOR_LABEL = 250   # eligibility for breakout label
BREAKOUT_PERCENTILE = 0.85     # top 15% within season
ABS_Z_THRESHOLD = 1.5          # ALSO require at least +1.5 SD absolute improvement (set None to disable)
# ------------------------



def normalize_cols(cols):
    out = []
    for c in cols:
        c2 = c.strip().lower().replace("%", " percent")
        c2 = re.sub(r"[^a-z0-9]+", "_", c2).strip("_")
        out.append(c2)
    return out

# Map many common names to consistent ones we’ll use
RENAME = {
    "player_id":"player_id", "player_name":"player_name",
    "season":"season", "year":"season",
    "pa":"pa", "plate_appearances":"pa",

    # counts for ratios
    "bb":"bb", "so":"so", "whiffs":"whiffs", "swings":"swings", "takes":"takes",
    "bip":"bip", "barrels_total":"barrels_total",

    # percents / rates (as provided)
    "hardhit_percent":"hardhit_percent",
    "barrels_per_bbe_percent":"barrels_per_bbe_percent",

    # useful context (not fed directly to model here)
    "launch_speed":"launch_speed",
    "launch_angle":"launch_angle",
    "attack_angle":"attack_angle",
    "rate_ideal_attack_angle":"rate_ideal_attack_angle",
}

dfs = []
for year, path in DATA_PATHS.items():
    tmp = pd.read_csv(path)
    tmp.columns = normalize_cols(tmp.columns)
    tmp = tmp.rename(columns={k:v for k,v in RENAME.items() if k in tmp.columns})
    tmp["season"] = year  # inject season from filename
    dfs.append(tmp)

df = pd.concat(dfs, ignore_index=True)

# Keep one row per player-season (if your files are already season-level this is a no-op)
group_keys = ["player_id", "player_name", "season"]
agg = {c: "mean" for c in df.columns if c not in group_keys}
df = df.groupby(group_keys, as_index=False).agg(agg)

# Basic filters
df = df[df["season"] >= MIN_SEASON]
df = df[df["pa"] >= MIN_PA_FOR_ROW]
df = df.sort_values(["player_id","season"]).reset_index(drop=True)

print("Loaded columns:", sorted(df.columns.tolist()))
print("Seasons:", sorted(df["season"].unique().tolist()))
print("Rows:", len(df))



def safe_div(numer, denom):
    return numer / (denom.replace(0, np.nan) + 1e-6)

def pct_to_rate(series):
    """Convert a percent-like column to fraction if values look like 0–100."""
    s = series.copy()
    if s.dropna().mean() > 1.0:  # crude but works: e.g., 45.0% → 0.45
        s = s / 100.0
    return s

# Ensure required base columns exist (fill with 0 if missing in early seasons)
for col in ["bb","so","whiffs","swings","takes","bip","barrels_total",
            "hardhit_percent","barrels_per_bbe_percent","pa"]:
    if col not in df.columns:
        df[col] = 0.0

# Convert percentage columns to rates
df["hardhit_rate"] = pct_to_rate(df["hardhit_percent"])
df["barrel_bbe_rate"] = pct_to_rate(df["barrels_per_bbe_percent"])

# batted balls proxy (if bip exists, use it)
df["batted_balls"] = df["bip"]  # season-level Balls In Play (already present in your CSVs)

# --- Ratios / per-PA features (season level) ---
# Discipline / contact
df["bb_per_pa"]        = safe_div(df["bb"], df["pa"])
df["k_per_pa"]         = safe_div(df["so"], df["pa"])
df["bb_k_ratio"]       = df["bb"] / (df["so"] + 1e-6)

df["whiff_per_swing"]  = safe_div(df["whiffs"], df["swings"])
df["whiffs_per_pa"]    = safe_div(df["whiffs"], df["pa"])
df["swings_per_pa"]    = safe_div(df["swings"], df["pa"])
df["takes_per_pa"]     = safe_div(df["takes"],  df["pa"])

# Contact rate forms
df["contact_rate"]        = (df["swings"] - df["whiffs"]) / (df["swings"] + 1e-6)
df["contact_per_pa"]      = (df["swings"] - df["whiffs"]) / (df["pa"] + 1e-6)

# Power / quality per opportunity
df["hardhit_per_pa"]      = df["hardhit_rate"] * safe_div(df["batted_balls"], df["pa"])
df["barrels_per_pa"]      = safe_div(df["barrels_total"], df["pa"])
df["barrels_per_swing"]   = safe_div(df["barrels_total"], df["swings"])

# Power Index per PA = (HardHit% + Barrels/BBE%) * (batted_balls / PA)
df["power_index_per_pa"]  = (df["hardhit_rate"] + df["barrel_bbe_rate"]) * safe_div(df["batted_balls"], df["pa"])

ratio_cols = [
    "bb_per_pa","k_per_pa","bb_k_ratio",
    "whiff_per_swing","whiffs_per_pa","swings_per_pa","takes_per_pa",
    "contact_rate","contact_per_pa",
    "hardhit_per_pa","barrels_per_pa","barrels_per_swing","power_index_per_pa",
]

print("Built ratio features:", ratio_cols)
df[["player_name","season"] + ratio_cols].head()



# For delta building, we only need the ratio columns + keys + PA for eligibility
# List of ratio features (already in your pipeline)
RATIO_FEATURES = [
    "bb_per_pa", "k_per_pa", "bb_k_ratio", 
    "whiff_per_swing", "whiffs_per_pa",
    "hardhit_per_pa", "barrels_per_pa", "barrels_per_swing",
    "power_index_per_pa", "contact_rate", "contact_per_pa",
    "takes_per_pa", "swings_per_pa"
]

# New raw skill features
RAW_FEATURES = [
    "launch_speed", "hardhit_percent", "barrels_per_bbe_percent",
    "bat_speed", "attack_angle", "rate_ideal_attack_angle"
]

# Add PA context
CONTEXT_FEATURES = ["pa"]

ALL_FEATURES = RATIO_FEATURES + RAW_FEATURES + CONTEXT_FEATURES

def compute_deltas(group):
    g = group.sort_values("season").copy()
    
    # ratio + raw features
    for col in RATIO_FEATURES + RAW_FEATURES:
        if col in g.columns:
            g[f"{col}_prev"]  = g[col].shift(1)
            g[f"{col}_delta"] = g[col] - g[f"{col}_prev"]
    
    # toward-opt deltas for angles
    if {"attack_angle","attack_angle_prev"}.issubset(g.columns):
        g["attack_angle_toward_opt_delta"] = (
            np.abs(g["attack_angle_prev"] - 8) - np.abs(g["attack_angle"] - 8)
        )
    if {"rate_ideal_attack_angle","rate_ideal_attack_angle_prev"}.issubset(g.columns):
        g["rate_ideal_attack_angle_delta"] = (
            g["rate_ideal_attack_angle"] - g["rate_ideal_attack_angle_prev"]
        )

    # PA context
    if "pa" in g.columns:
        g["pa_prev"]  = g["pa"].shift(1)
        g["pa_delta"] = g["pa"] - g["pa_prev"]
    
    return g

# Apply per player
df_d = df.groupby("player_id", group_keys=False).apply(compute_deltas)




# ==== From df_d (has *_delta columns) -> z-score, label, export ====

# 1) Which delta features feed the process_score? (exclude PA context)
all_delta_features = sorted([c for c in df_d.columns if c.endswith("_delta")])
score_delta_features = [c for c in all_delta_features if c not in {"pa_delta"}]

print("Delta features (total):", len(all_delta_features))
print("Delta features used in process_score (excl. pa_delta):", len(score_delta_features))

# 2) Z-score by season for process features only
def zscore_by_season(frame, cols):
    out = frame.copy()
    for c in cols:
        mu = out.groupby("season")[c].transform("mean")
        sd = out.groupby("season")[c].transform("std").replace(0, np.nan)
        out[c] = (out[c].fillna(0.0) - mu) / sd
        out[c] = out[c].fillna(0.0)
    return out

df_z = zscore_by_season(df_d.copy(), score_delta_features)

# 3) Build process_score (equal-weight sum of z-scored deltas)
df_z["process_score"] = df_z[score_delta_features].sum(axis=1)

# 4) Label breakouts: top percentile AND absolute z threshold (if set)
df_z["breakout_label"] = 0
eligible = (df_z["pa"] >= MIN_PA_FOR_LABEL)

for s, grp in df_z.groupby("season"):
    idx = grp.index
    cutoff = np.percentile(grp["process_score"], 100 * BREAKOUT_PERCENTILE)
    mask = grp["process_score"] >= cutoff
    if ABS_Z_THRESHOLD is not None:
        mask = mask & (grp["process_score"] >= ABS_Z_THRESHOLD)
    df_z.loc[idx, "breakout_label"] = (mask & eligible.loc[idx]).astype(int)

df_z["labeled_year"] = df_z["season"]

print("Label balance by season:")
print(df_z.groupby("season")["breakout_label"].value_counts().unstack(fill_value=0))

# 5) Export: include IDs, PA context, ALL deltas (ratios + your added raw-skill deltas),
#    and the 3 label columns we just created
export_cols = (
    ["player_id","player_name","season","pa","pa_prev","pa_delta",
     "process_score","breakout_label","labeled_year"]
    + all_delta_features
)

existing = [c for c in export_cols if c in df_z.columns]
missing  = [c for c in export_cols if c not in df_z.columns]
if missing:
    print("Note: missing columns skipped ->", missing)

OUTFILE = "../outputs/combined_breakouts_and_nonbreakouts_2022_2025_ratio_plus_raw.csv"
df_z[existing].to_csv(OUTFILE, index=False)
print(f"Saved to: {OUTFILE} | Features exported: {len(all_delta_features)} | Rows: {len(df_z)}")



# ==== EXPORT (use df_z, not df_d) ====

# Collect all delta features (ratios + raw-skill + toward-opt)
all_delta_features = sorted([c for c in df_z.columns if c.endswith("_delta")])

export_cols = (
    ["player_id","player_name","season","pa","pa_prev","pa_delta",
     "process_score","breakout_label","labeled_year"]
    + all_delta_features
)

# sanity check
missing = [c for c in export_cols if c not in df_z.columns]
if missing:
    print("Missing columns (will be skipped):", missing)

existing = [c for c in export_cols if c in df_z.columns]

OUTFILE = "../outputs/combined_breakouts_and_nonbreakouts_2022_2025_ratio_plus_raw.csv"
df_z[existing].to_csv(OUTFILE, index=False)

print(f"Saved to: {OUTFILE}")
print("Rows:", len(df_z), "| Features exported:", len(all_delta_features))










